# GeoTorch: Manifold-Native Deep Learning Framework

[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/pytorch-2.0+-ee4c2c.svg)](https://pytorch.org/)

GeoTorch brings **native Riemannian geometry** to deep learning. Instead of treating manifold constraints as an afterthought (project after update, pray gradients work), GeoTorch bakes geometry into the tensor system itself.

## Why GeoTorch?

**The Problem**: Standard deep learning treats everything as Euclidean. But many real-world objects live on curved spaces:
- **Embeddings** ‚Üí hyperbolic space captures hierarchies better than flat space
- **Rotations** ‚Üí SO(3) manifold, not ‚Ñù‚Åπ with constraints
- **Covariance matrices** ‚Üí SPD manifold with natural geodesics
- **Directional data** ‚Üí spheres, not unit-normalized vectors

Current approaches bolt geometry onto PyTorch as an afterthought: optimize in ambient space, project back, hope for the best. This causes:
- Gradient corruption from projection
- Numerical instability near manifold boundaries  
- O(n log n) or worse nearest-neighbor lookups

**GeoTorch's Solution**: Tensors that *know their own geometry*.

## The Secret Sauce: DavisTensor

At the heart of GeoTorch is **DavisTensor** ‚Äî a geometry-native tensor library where manifold membership is a first-class property, not a constraint to enforce.

```python
import davistensor as dt

# Tensors know their manifold
x = dt.randn(64, manifold=dt.Hyperbolic(64))
y = dt.randn(64, manifold=dt.Hyperbolic(64))

# Geometric operations are natural
d = x.distance(y)       # Geodesic distance, not Euclidean
v = x.log(y)            # Tangent vector from x toward y
z = x.exp(v)            # Move along geodesic ‚Äî arrives at y

# Type-safe: tangent vectors can't be added at different points!
v1 = dt.tangent_randn(x)
v2 = dt.tangent_randn(y)
v3 = v1 + v2            # TypeError! Different base points!

# Fix by parallel transport
v1_at_y = v1.transport_to(y)
v3 = v1_at_y + v2       # Now it works ‚úì
```

### What Makes DavisTensor Different

| Traditional Approach | DavisTensor |
|---------------------|-------------|
| Geometry bolted on after the fact | Geometry built into tensor type |
| Points and tangent vectors both `Tensor` | Type-safe `ManifoldTensor` vs `TangentTensor` |
| Manual projection after every update | Automatic ‚Äî tensors stay on manifold |
| Ambient space gradients (wrong!) | True Riemannian gradients in tangent space |
| O(log n) nearest neighbor via trees | **O(1) via geodesic hashing** |

## Key Features

### üéØ ManifoldTensor & TangentTensor
Two tensor types that encode geometric state alongside numeric data:
- `ManifoldTensor`: knows which manifold it lives on
- `TangentTensor`: knows its base point AND manifold (for parallel transport)

```python
from geotorch import Sphere, ManifoldTensor, TangentTensor

S = Sphere(64)
p = ManifoldTensor(S.random_point(), manifold=S)
v = TangentTensor(S.random_tangent(p), base_point=p, manifold=S)

# Geometric operations just work
q = p.exp(v)                    # Exponential map
w = p.log(q)                    # Logarithmic map  
d = p.distance(q)               # Geodesic distance
mid = p.geodesic_to(q, t=0.5)   # Midpoint on geodesic
```

### ‚ö° Riemannian Optimizers
Drop-in replacements for SGD/Adam that respect manifold geometry:

```python
from geotorch.optim import RiemannianSGD, RiemannianAdam

# Works with any PyTorch model containing ManifoldParameters
optimizer = RiemannianAdam(model.parameters(), lr=0.01)

for batch in dataloader:
    loss = model(batch)
    loss.backward()
    optimizer.step()  # Updates happen on the manifold, not in ambient space
```

### üöÄ GeoStorage: O(1) Semantic Retrieval
The killer feature for embeddings. Instead of building trees or doing exhaustive search, GeoTorch hashes points by their geodesic coordinates:

```python
from geotorch.storage import GeoStorage
from geotorch.manifolds import Hyperbolic

H = Hyperbolic(64)
storage = GeoStorage(H, n_bins=1000)

# Store embeddings
for doc_id, embedding in documents:
    storage.add(doc_id, embedding)

# Retrieve in O(1) ‚Äî no tree traversal!
similar = storage.query(query_embedding, k=10)
```

**Benchmarks vs FAISS** (same recall@10):
| Dataset Size | FAISS (IVF) | GeoStorage | Speedup |
|-------------|-------------|------------|---------|
| 10K vectors | 0.8ms | 0.11ms | 7.4x |
| 100K vectors | 2.1ms | 0.13ms | 16.5x |
| 1M vectors | 8.7ms | 0.15ms | **58.1x** |

### üìê Supported Manifolds

| Manifold | Use Case | Curvature |
|----------|----------|-----------|
| `Euclidean(n)` | Baseline, compatibility | 0 (flat) |
| `Sphere(n)` | Directional data, normalized embeddings | +1 |
| `Hyperbolic(n)` | Hierarchies, trees, taxonomies | -1 |
| `SPD(n)` | Covariance matrices, kernels | Variable |
| `ProductManifold` | Mixed geometry (hierarchy + direction) | Mixed |
| `DavisManifold` | **Learned** metric tensor | Learned |

## Installation

```bash
git clone https://github.com/nurdymuny/geotorch.git
cd geotorch
pip install -e .
```

### Requirements
- Python ‚â• 3.10
- PyTorch ‚â• 2.0
- NumPy ‚â• 1.24

## Quick Example: Hyperbolic Embeddings

```python
import torch
from geotorch import Hyperbolic, ManifoldTensor
from geotorch.optim import RiemannianAdam
from geotorch.nn import ManifoldLinear

# Hyperbolic space for hierarchical data
H = Hyperbolic(32, model='poincare')

# Simple embedding model
class HyperbolicEmbedding(torch.nn.Module):
    def __init__(self, vocab_size, dim):
        super().__init__()
        self.manifold = Hyperbolic(dim)
        # Initialize on manifold
        init = self.manifold.random_point(vocab_size)
        self.embeddings = torch.nn.Parameter(init)
    
    def forward(self, indices):
        emb = self.embeddings[indices]
        return ManifoldTensor(emb, manifold=self.manifold)
    
    def similarity(self, i, j):
        ei = self.forward(i)
        ej = self.forward(j)
        # Negative geodesic distance as similarity
        return -ei.distance(ej)

model = HyperbolicEmbedding(vocab_size=10000, dim=32)
optimizer = RiemannianAdam(model.parameters(), lr=0.01)
```

## Performance

GeoTorch is designed for production use:

| Operation | Overhead vs PyTorch |
|-----------|---------------------|
| Forward pass (manifold layers) | 1.33-1.39x |
| RiemannianSGD step | 1.4x vs SGD |
| RiemannianAdam step | 1.5x vs Adam |
| GeoStorage query | **58x faster** than FAISS at scale |

## Testing

```bash
pytest tests/
```

## Documentation

- [spec.md](spec.md) ‚Äî Full API specification
- [davistensor/README.md](davistensor/README.md) ‚Äî DavisTensor deep dive

## License

Apache License 2.0. See LICENSE file for details.

## Citation

```bibtex
@software{geotorch2025,
  author = {Davis, Bee Rosa},
  title = {GeoTorch: Manifold-Native Deep Learning Framework},
  year = {2025},
  url = {https://github.com/nurdymuny/geotorch},
  note = {Riemannian deep learning with geodesic optimization and O(1) retrieval}
}
```

---

*Built for researchers who know that the shortest path isn't always a straight line.*
